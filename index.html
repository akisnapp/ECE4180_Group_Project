<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Project: 3D GPU</title>
</head>
<body>
  <h1>Project: 3D GPU</h1>
  <li>Alexander Snapp</li>
  <li>John Donahoe</li>
  <li>Andrew McBurnett</li>
  <h2>Project Description</h2>
    <p>This project uses Mbed LPC1768 to operate on data pulled from an HC-SR04 ultrasonic sensor and an BNO-055 IMU in order to track the movement of a device in 3D space, and
      then send this data over to a computer via serial after which it is processed in a GPU pipeline. This allows users to draw in 3-D space in real-time by physically moving the embedded system 
      in the real world, and then seeing this transferred over to a 3-D virtual drawing environment in real-time. The code we designed for the GPU pipeline was a custom GPU pipeline 
      in Python that was based off of the Direct3D API (which is a subset of DirectX). This allowed world space coordinates calculated by the Mbed to be transferred over to this pipeline 
      and then provide live updates on the GUI so that it was easier for users to draw.
    </p>
  <h2>Usage and Demonstration</h2>
  <h3>Instructions</h3>
  <ol>
    <li>Connect the MBed to a PC running the application.</li>
    <li>Move the device to move your location in 3D space.</li>
    <li>Hold down the 'draw' pushbutton to trace your movement on the GUI and draw in 3D space.</li>
    <li>Release the button to stop drawing.</li>
  </ol>
  <h3>User Inputs/Controls from Mbed</h3>
  <ol>
    <li>'Pen' up/down via first pushbutton</li>
    <li>Location reset​ via second pushbutton</li>
    <li>Color control​ in RGB via 3 potentiometers</li>
  </ol>
  <h3>User Inputs/Controls from Pipeline</h3>
  <ol>
    <li>Camera position and view direction​</li>
    <li>Diffuse lighting (light source position & color)​</li>
    <li>Field of View (FoV), near frustum, and far frustum​</li>
    <li>Object location and rotation​</li>
  </ol>
  <h3>Video Demonstration</h2>
  <iframe width="560" height="315" src="https://www.youtube.com/embed/1Yy-fVK64YQ?si=8xQCNw8dnHe8JZTY" frameborder="0" allowfullscreen></iframe>
  <h2>Code</h2>
  <img src="https://github.com/ECE41803DPEN/ECE4180_Group_Project/blob/main/IMG/Picture1.png?raw=true" alt="IMAGE_ALT_TEXT" width="560" height="315">
  <img src="https://github.com/ECE41803DPEN/ECE4180_Group_Project/blob/main/IMG/Picture2.png?raw=true" alt="IMAGE_ALT_TEXT" width="560" height="315">
  <p>
    Our code worked by using the Mbed code below to sample data from the hardware and then use this data to add to or subtract from a corresponding value in an array which 
    stored the previous location the user was last at in world space when data was previously sampled. While doing this, the code also provides audio to allow the user to know 
    whether they are drawing (a pushbutton is used to indicate whether the user wants to be in 'pen' down mode) and uses input from 3 different potentiometers to determine the 
    color the user wants to draw with. This color is additionally displayed to an RGB LED so the user can more easily decide what color they would like to use before they enter 
    'pen' down mode. Additionally the Mbed accounts for one additional pushbutton which allows the user to reset the current location they are at in the real world to (0, 0, 0) so 
    that they can relocate themselves to the center of the virtual environment easily and then continue drawing from there. After all these calculations are done alongside with the 
    extra features being updated, the code proceeds to serially send the world space calculations along with the users chosen RGB color to the computer it is connected to where 
    the GPU pipeline programmed in Python takes over.<br><br>
    Once the GPU pipelines camera information and virtual environment has been set up (which happens in parallel with the Mbed coding undergoing its setup before entering its loop), then 
    it proceeds into a loop where each coordinate is calculated and rendered onto the GUI in a continuous stream as data comes in so that it is easier for the user to see what they 
    are drawing. It does this by doing a series of matrix multiplications which are supported by NumPy. Each point given from the Mbed creates a triangle with the point behind it and the 
    next point. The third vertex of the triangle comes from the midpoint of the 2 points plus the normalized cross product. Following this, the matrix multiplications on these vertices coordinates 
    begin. These matrix multiplications initially start off with the coordinates being multiplied by the rotation and translation matrices, followed by view transforms being applied and 
    then perspective transforms being applied. After this Z-Sorting is necessary at the end to draw items from back to front, so the user sees the closest items at the frontmost part of their 
    view and doesn't see items covered to their view by this item. After this viewport transforms are applied and the coordinates are all rendered to the GUI in screenspace.
  </p>
  <h2>Mbed Code</h2>
 <div id="code-container" style="width: 1000px; height: 500px; overflow-y: scroll; border: 1px solid #ddd; padding: 10px; background-color: #f8f9fa;">
<pre style="font-family: monospace; font-size: 14px; line-height: 1.5; padding: 10px; background-color: #f0f0f0;">
#include &ltAdafruit_Sensor.h&gt
#include &ltAdafruit_BNO055.h&gt
#include &ltimumaths.h&gt
#include "mbed.h"
#include "ultrasonic.h"

//Set the delay constant for waiting for cycles to complete
#define BNO055_SAMPLERATE_DELAY_MS (100)

Serial pc(USBTX, USBRX);
I2C i2c(p9, p10);
Adafruit_BNO055 bno = Adafruit_BNO055(-1, BNO055_ADDRESS_A, &i2c);

PwmOut speaker(p21);

DigitalIn button(p22);
DigitalIn reset(p23);

PwmOut re(p26);
PwmOut gr(p25);
PwmOut bl(p24);

AnalogIn red(p20);
AnalogIn green(p19);
AnalogIn blue(p18);

float location[3] = {0.0, 0.0, 0.0};
int prev_height = 0;
int prev = 1;
float init_height;


void dist(int distance)
{
    //update y coordinate based on height readings and initialization constant calculated below
    if (reset == 0) {
        location[1] = 0;
        prev_height = 0;
    } else {
        if (distance > prev_height + 5) {
            location[1] = init_height - 5;
        } else if (distance < prev_height - 5) {
            location[1] = init_height + 5;
        } else {
            location[1] = init_height - (distance / 10.0);
        }
    }

    if (!init_height) {
        init_height = distance / 10.0;
    }

}


ultrasonic mu(p6, p7, .1, 1, &dist);    //Set the trigger pin to p6 and the echo pin to p7
                                        //have updates every .1 seconds and a timeout after 1
                                        //second, and call dist when the distance changes


void loop();

/*************************************************************************

    setup function for initializing location statistics and starting data sampling

*************************************************************************/
int main()
{
  pc.baud(115200);
  pc.printf("Orientation Sensor Raw Data Test\r\n");

  mu.startUpdates();
  button.mode(PullUp);
  reset.mode(PullUp);
  //mu.startUpdates();//start measuring the distance

  //Initialise sensor
  if(!bno.begin())
  {
    //bno-055 not detected
    pc.printf("Ooops, no BNO055 detected ... Check your wiring or I2C ADDR!\r\n");
    while(1);
  }
  else
    pc.printf("BNO055 was detected!\r\n");

  wait(1);
  
  mu.checkDistance();

  //int[] location = {0, 0, 0};

  // print the temperature during setup (if 0 C this is indicator the bno-055 clock needs to be reset)
  int8_t temp = bno.getTemp();
  pc.printf("Current Temperature: %d C\r\n", temp);
  bno.setExtCrystalUse(true);

  pc.printf("Calibration status values: 0=uncalibrated, 3=fully calibrated\r\n");

  while(true)
      loop();
}

/*************************************************************************

    Loop what happens continuously, used to calculate color, update location and send data over serial port
    each time that it is called
    
**************************************************************************/
void loop(void)
{
    //color calculations from potentiometers
    int b = (int) (blue * 255); //blue
    int g = (int) (green * 255); //green
    int r = (int) (red * 255); //red

    //update rgb led with color the user is currently using
    re = red;
    gr = green;
    bl = blue;

    mu.checkDistance();  //the class checks if dist needs to be called.

    //get vector data in euler angles, function uses quanternion data to get euler data
    imu::Vector<3> euler = bno.getVector(Adafruit_BNO055::VECTOR_EULER);
    
    //location calculations
    if (reset == 0) { //reset to initial starting point
        location[0] = 0;
        location[2] = 0;
    } else {
        if (euler.y() / 3 > 5) { //catch for if movement is too much
            location[2] += 5;
        } else {
            location[2] += euler.y() / 3;
        }
        if (euler.z() / 3 > 5) { //catch for if movement is too much
            location[0] += 5;
        } else {
            location[0] += euler.z() / 3;
        }
    }

    if (button == 0) { //print data to serial so that it is accessible by the python script
        
        //pc.printf("EULER: X: %f Y: %f Z: %f\r\n", euler.x(), euler.y(), euler.z());
        pc.printf("X: %f Y: %f Z: %f\r\n", location[0], location[1], location[2]);
        pc.printf(" @%d,%d,%d\r\n",r, g, b);
        speaker = 0.3; //speaker on to let user know they are drawing

    } else {
        speaker = 0; //speaker off to let user know that they are not drawing
    }

    //check if there is a break statement between drawings so that python code knows to leave a gap for 'pen up'
    if (prev == 0 && button == 1) { 
        pc.printf("b\r\n");
    }
    prev = button;



  //calibration status update for each sensor.
  uint8_t system, gyro, accel, mag = 0;
  bno.getCalibration(&system, &gyro, &accel, &mag);
  //pc.printf("CALIBRATION: Sys=%d, Gyro=%d, Accel=%d, Mag=%d\r\n", (int)(system), (int)(gyro), (int)(accel), (int)(mag));
  wait_ms(BNO055_SAMPLERATE_DELAY_MS * 2);
}

</pre>
</div>
  <h2>Python Code</h2>
<div id="code-container" style="width: 1000px; height: 500px; overflow-y: scroll; border: 1px solid #ddd; padding: 10px; background-color: #f8f9fa;">
<pre style="font-family: monospace; font-size: 14px; line-height: 1.5; padding: 10px; background-color: #f0f0f0;">
import serial
import time
import numpy as np
import pygame
import math
from pygame.locals import (
    K_ESCAPE,
    KEYDOWN,
)

ser = serial.Serial(port='COM3',baudrate=115200,parity=serial.PARITY_NONE,stopbits=serial.STOPBITS_ONE,bytesize=serial.EIGHTBITS,timeout=0)

c = 0

scale = 20

color = [0,0,255]
lightSource = np.matrix([4, 7, 10])  # x, y, z
cameraLocation = np.matrix([6, -10, 0])  # x, y, z
cameraPointing = np.matrix([0, 1, 0])  # x, y, z
objectLocation = [0, 0, 0]  # x, y, z
xRotation = 0  # degrees
yRotation = 0  # degrees
zRotation = 0  # degrees
fieldOfView = 120
nearFrustum = -50  # z
farFrustum = 80  # z
M_diff = [.259, .29, .322, 1]  # r g b a

up = np.matrix([0, -1, 0])
screenheight = 1000
screenwidth = 1000

lightSource = lightSource / (np.linalg.norm(lightSource))

# Rotation Matrices Creation
xRotMatrix = np.matrix([
    [1, 0, 0, 0],
    [0, round(math.cos(math.radians(xRotation)), 5), round(math.sin(math.radians(xRotation)), 5), 0],
    [0, round(-math.sin(math.radians(xRotation)), 5), round(math.cos(math.radians(xRotation)), 5), 0],
    [0, 0, 0, 1]
], dtype=float)

yRotMatrix = np.matrix([
    [round(math.cos(math.radians(yRotation)), 5), 0, round(-math.sin(math.radians(yRotation)), 5), 0],
    [0, 1, 0, 0],
    [round(math.sin(math.radians(yRotation)), 5), 0, round(math.cos(math.radians(yRotation)), 5), 0],
    [0, 0, 0, 1]
], dtype=float)

zRotMatrix = np.matrix([
    [round(math.cos(math.radians(zRotation)), 5), round(math.sin(math.radians(zRotation)), 5), 0, 0],
    [round(-math.sin(math.radians(zRotation)), 5), round(math.cos(math.radians(zRotation))), 0, 0],
    [0, 0, 1, 0],
    [0, 0, 0, 1]
], dtype=float)
# End Rotation Matrices Creation


# Translation Matrix Creation
translateMatrix = np.matrix([
    [1, 0, 0, 0],
    [0, 1, 0, 0],
    [0, 0, 1, 0],
    [int(objectLocation[0]), int(objectLocation[1]), int(objectLocation[2]), 1]
], dtype=float)
# End Translate Matrix Creation

zaxis = (cameraPointing - cameraLocation) / (np.linalg.norm((cameraPointing - cameraLocation)))
xaxis = (np.cross(up, zaxis)) / (np.linalg.norm(np.cross(up, zaxis)))
yaxis = np.cross(zaxis, xaxis)

viewMatrix = np.matrix([
    [xaxis.item(0), yaxis.item(0), zaxis.item(0), 0],
    [xaxis.item(1), yaxis.item(1), zaxis.item(1), 0],
    [xaxis.item(2), yaxis.item(2), zaxis.item(2), 0],
    [-np.dot(xaxis, cameraLocation.T).item(0), -np.dot(yaxis, cameraLocation.T).item(0), -np.dot(zaxis, cameraLocation.T).item(0), 1]
], dtype=float)
# End View Matrix Creation

# Perspective Matrix Creation
FOVy = math.radians(fieldOfView)
aspect = screenheight / screenwidth
zn = nearFrustum
zf = farFrustum
yScale = 1 / (math.tan(FOVy/2))
xScale = yScale

perspectiveMatrix = np.matrix([
    [xScale, 0, 0, 0],
    [0, yScale, 0, 0],
    [0, 0, zf/(zf-zn), 1],
    [0, 0, -zn*zf/(zf-zn), 0]
], dtype=float)

# End Perspective Matrix Creation



# UNUSED FUNCTION
def updateCamera():
    cameraLocation = np.matrix([20*math.cos(c), 20*math.sin(c), 0])
    n = np.matrix([-math.cos(c), -math.sin(c), 0], dtype=float)
    cameraPointing = np.matrix([n.item(0), n.item(1), n.item(2)])

    zaxis = (cameraPointing - cameraLocation) / (np.linalg.norm((cameraPointing - cameraLocation)))
    xaxis = (np.cross(up, zaxis)) / (np.linalg.norm(np.cross(up, zaxis)))
    yaxis = np.cross(zaxis, xaxis)

    viewMatrix = np.matrix([
        [xaxis.item(0), yaxis.item(0), zaxis.item(0), 0],
        [xaxis.item(1), yaxis.item(1), zaxis.item(1), 0],
        [xaxis.item(2), yaxis.item(2), zaxis.item(2), 0],
        [-np.dot(xaxis, cameraLocation.T).item(0), -np.dot(yaxis, cameraLocation.T).item(0),
         -np.dot(zaxis, cameraLocation.T).item(0), 1]
    ], dtype=float)
    # End View Matrix Creation

    # Perspective Matrix Creation
    FOVy = math.radians(fieldOfView)
    aspect = screenheight / screenwidth
    zn = nearFrustum
    zf = farFrustum
    yScale = 1 / (math.tan(FOVy / 2))
    xScale = yScale

    perspectiveMatrix = np.matrix([
        [xScale, 0, 0, 0],
        [0, yScale, 0, 0],
        [0, 0, zf / (zf - zn), 1],
        [0, 0, -zn * zf / (zf - zn), 0]
    ], dtype=float)

    # End Perspective Matrix Creation



# pass in an array, and it returns an array of fully pipelined and Z-sorted points
def pipeline(tuples):
    preAnythingMatrices = [] # must be formatted as [[x, y, z], [x, y, z], [x, y, z], [x, y, z],...]
    i = 1
    if len(tuples) == 1:
        return -1
    while i < len(tuples):
        v1 = tuples[i - 1]
        v2 = tuples[i]
        v1 = np.matrix([v1[0], v1[1], v1[2]], dtype=float)
        v2 = np.matrix([v2[0], v2[1], v2[2]], dtype=float)
        cr = np.cross(v1, v2)
        unit = np.linalg.norm(cr) / 100.0
        vert3PreOrtho = np.matrix([
                            (tuples[i - 1][0] + tuples[i][0]) / 2,
                            (tuples[i - 1][1] + tuples[i][1]) / 2,
                            (tuples[i - 1][2] + tuples[i][2]) / 2])
        v3 = np.add(vert3PreOrtho, unit)

        v1 = np.matrix([v1.item(0), v1.item(1), v1.item(2), 1], dtype=float)
        v2 = np.matrix([v2.item(0), v2.item(1), v2.item(2), 1], dtype=float)

        v3 = np.matrix([
            v3.item(0),
            v3.item(1),
            v3.item(2),
            1
        ])
        preAnythingMatrices.append([v1, v2, v3])
        i += 1

    # World Transforms
    afterWorldMatrices = []
    for i in preAnythingMatrices:
        vert1 = i[0] @ xRotMatrix @ yRotMatrix @ zRotMatrix @ translateMatrix
        vert2 = i[1] @ xRotMatrix @ yRotMatrix @ zRotMatrix @ translateMatrix
        vert3 = i[2] @ xRotMatrix @ yRotMatrix @ zRotMatrix @ translateMatrix
        afterWorldMatrices.append([vert1, vert2, vert3])

    afterViewMatrices = []
    # View Transforms
    for i in afterWorldMatrices:
        vert1 = i[0] @ viewMatrix
        vert2 = i[1] @ viewMatrix
        vert3 = i[2] @ viewMatrix
        afterViewMatrices.append([vert1, vert2, vert3])

    afterPerspectiveMatrices = []
    # Perspective Transforms
    for i in afterViewMatrices:
        vert1 = i[0] @ perspectiveMatrix
        vert2 = i[1] @ perspectiveMatrix
        vert3 = i[2] @ perspectiveMatrix
        afterPerspectiveMatrices.append([vert1, vert2, vert3])

    # Z sorting the matrices
    zAverages = []
    for i in afterPerspectiveMatrices:
        vert1 = i[0].item(2)
        vert2 = i[1].item(2)
        vert3 = i[2].item(2)
        zAverages.append((vert1 + vert2 + vert3) / 3)

    zSorting = np.argsort(zAverages)
    zSorting = zSorting.tolist()
    afterPerspectiveMatrices = [afterPerspectiveMatrices[ind] for ind in zSorting]
    afterWorldMatrices = [afterWorldMatrices[ind] for ind in zSorting]

    # Divide by WZ
    for i in afterPerspectiveMatrices:
        if (i[0].item(2) != 0):
            i[0] = np.matrix([i[0].item(0) / i[0].item(2), i[0].item(1) / i[0].item(2), i[0].item(2) / i[0].item(2),
                              i[0].item(3) / i[0].item(2)])
        if (i[1].item(2) != 0):
            i[1] = np.matrix([i[1].item(0) / i[1].item(2), i[1].item(1) / i[1].item(2), i[1].item(2) / i[1].item(2),
                              i[1].item(3) / i[1].item(2)])
        if (i[2].item(2) != 0):
            i[2] = np.matrix([i[2].item(0) / i[2].item(2), i[2].item(1) / i[2].item(2), i[2].item(2) / i[2].item(2),
                              i[2].item(3) / i[2].item(2)])

    afterViewPortMatrices = []
    # ViewPort Transforms
    for i in afterPerspectiveMatrices:
        vert1 = np.matrix([(screenwidth * .5 * i[0].item(0) + (screenwidth * .5)),
                           (screenheight * .5 * i[0].item(1)) + (screenheight * .5), i[0].item(2), i[0].item(3)])

        vert2 = np.matrix([(screenwidth * .5 * i[1].item(0) + (screenwidth * .5)),
                           (screenheight * .5 * i[1].item(1)) + (screenheight * .5), i[1].item(2), i[1].item(3)])

        vert3 = np.matrix([(screenwidth * .5 * i[2].item(0) + (screenwidth * .5)),
                           (screenheight * .5 * i[2].item(1)) + (screenheight * .5), i[2].item(2), i[2].item(3)])

        afterViewPortMatrices.append([vert1, vert2, vert3])

    return afterViewPortMatrices


pointCache = {1:[], 2:[], 3:[]} # each array is a collection of points, that connect to eachother sequentially. Each new
                                # key/value is a break in the lines. Tuple of points.

colors = {1:(255, 0, 0), 2:(255, 0, 0)}

pygame.init()
screen = pygame.display.set_mode([1000, 1000])
running = True

counter = 1

while running:
    try:
        s = ser.readline().decode()
        #print(s)
        if 'X:' in s:
            print(s)
            #print(s[3:9])
            newarr = []
            #print(float(s[3:8]))
            a1 = s.split(": ")
            newarr.append(float(a1[1][0:6]))
            newarr.append(float(a1[2][0:6]))
            newarr.append(float(a1[3][0:6]))
            if counter in pointCache.keys():
                pointCache[counter].append(newarr)
            else:
                pointCache[counter] = [newarr]


        if "@" in s:
            print(s)
            color = (int(s.split("@")[1].split(",")[0]),
                int(s.split("@")[1].split(",")[1]),
                int(s.split("@")[1].split(",")[2]))

            colors[counter] = color

        if 'b' in s:
            counter += 1
        time.sleep(.1)
    except:
        print("fail")
        time.sleep(.1)

    for event in pygame.event.get():
        if event.type == pygame.QUIT:
            running = False
        if event.type == KEYDOWN:
            if event.key == K_ESCAPE:
                running = False
    screen.fill((255, 255, 255))

    for k,v in pointCache.items():
        if len(v) == 0 or len(v) == 1:
            continue
        afterViewPortMatrices = pipeline(v)
        if afterViewPortMatrices == -1:
            continue
        for i in range(len(afterViewPortMatrices)):

            v1 = (afterViewPortMatrices[i][0].item(0), afterViewPortMatrices[i][0].item(1))
            v2 = (afterViewPortMatrices[i][1].item(0), afterViewPortMatrices[i][1].item(1))
            v3 = (afterViewPortMatrices[i][2].item(0), afterViewPortMatrices[i][2].item(1))
            if v1[0] < 0 or v1[1] < 0:
                continue
            if v2[0] < 0 or v2[0] < 0:
                continue
            if v3[0] < 0 or v3[0] < 0:
                continue

            pygame.draw.polygon(screen, colors[k], (v1, v2, v3))


    pygame.display.flip()
    #c = c + .05
    #updateCamera()

pygame.quit()
</pre>
</div>

  <h2>Hardware</h2>
  <img src="https://github.com/ECE41803DPEN/ECE4180_Group_Project/blob/main/IMG/finalDiagram1.png?raw=true" alt="IMAGE_ALT_TEXT" width="560" height="315">
  <ul>
    <li>HC-SR04 Ultrasonic Distance sensor</li>
    <li>BNO-055 Absolute Orientation sensor (IMU)</li>
    <li>2 pushbuttons & 3 potentiometers</li>
    <li>RGB LED, 2 100Ω resistors, and 1 180Ω resistor</li>
    <li>Speaker</li>
    <li>TPA2005D1 Class D Audio Amp</li>
    <li>Mbed LPC1768</li>
  </ul>
  <h2>Contributions</h2>
  <ul>
    <li>Alexander Snapp: Hardware, MBed code, and parts of Python coding</li>
    <li>John Donahoe: MBed code, Python code</li>
    <li>Andrew McBurnett: Website documentation and hardware debugging</li>
  </ul>
</body>
</html>

